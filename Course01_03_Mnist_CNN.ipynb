{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course01-03-Mnist-CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dennis826/Machine-learning/blob/master/Course01_03_Mnist_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K7ubzkJiFsk6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Improving Computer Vision Accuracy using Convolutions"
      ]
    },
    {
      "metadata": {
        "id": "xvMqlDmAF3so",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Use DNN to regonize fashion mnist**"
      ]
    },
    {
      "metadata": {
        "id": "6AzNMUfUFel7",
        "colab_type": "code",
        "outputId": "218d4f98-e436-4183-d467-55931ac21f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.4911 - acc: 0.8270\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3723 - acc: 0.8638\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3333 - acc: 0.8791\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.3106 - acc: 0.8862\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2938 - acc: 0.8923\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.3460 - acc: 0.8743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Q0eN2O1GvN4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Add CNN to regonize fashion mnist**"
      ]
    },
    {
      "metadata": {
        "id": "lQ26FMfdG5th",
        "colab_type": "code",
        "outputId": "77ffdb33-1bac-43e8-abd3-d2c9100cd277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 113,386\n",
            "Trainable params: 113,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.4738 - acc: 0.8280\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3190 - acc: 0.8833\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.2748 - acc: 0.8991\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.2466 - acc: 0.9100\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.2209 - acc: 0.9184\n",
            "10000/10000 [==============================] - 1s 66us/sample - loss: 0.2711 - acc: 0.9031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5ZwXMFLfIhzi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Visualizing the Convolutions and Pooling**"
      ]
    },
    {
      "metadata": {
        "id": "QeN_FnygIk0A",
        "colab_type": "code",
        "outputId": "11387592-85ae-40c0-f140-2e68c8f1767e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FGbdExJBIqnt",
        "colab_type": "code",
        "outputId": "33917f74-8586-4d0b-9b4d-ee6ed80f6156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, axarr = plt.subplots(3,4)\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=7\n",
        "THIRD_IMAGE=26\n",
        "CONVOLUTION_NUMBER = 1\n",
        "\n",
        "from tensorflow.keras import models\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "\n",
        "for x in range(0,4):\n",
        "    f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "    axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "    axarr[0,x].grid(False)\n",
        "    f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "    axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "    axarr[1,x].grid(False)\n",
        "    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "    axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "    axarr[2,x].grid(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD8CAYAAACxUoU3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wK-Y52MXLHH0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4. EXERCISES**"
      ]
    },
    {
      "metadata": {
        "id": "Yglwpt8TLPOJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(1) Change convolutions to 16 or 128"
      ]
    },
    {
      "metadata": {
        "id": "dgSw-b5aLKKW",
        "colab_type": "code",
        "outputId": "1f2597e9-19d7-4cb5-a468-c9a51996b159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 11, 11, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               409728    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 559,882\n",
            "Trainable params: 559,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.4219 - acc: 0.8477\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2809 - acc: 0.8965\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.2347 - acc: 0.9125\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2013 - acc: 0.9255\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1712 - acc: 0.9347\n",
            "10000/10000 [==============================] - 1s 73us/sample - loss: 0.2693 - acc: 0.9024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CQ1z2mOsNFkt",
        "colab_type": "code",
        "outputId": "221a6ec2-341f-4591-ce50-d80620e86f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 11, 11, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 55,098\n",
            "Trainable params: 55,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.5140 - acc: 0.8111\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.3536 - acc: 0.8718\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 0.3061 - acc: 0.8890\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.2777 - acc: 0.8976\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.2563 - acc: 0.9041\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 0.2908 - acc: 0.8924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KlmTWsDWNb-F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(2) Remove the final Convolution"
      ]
    },
    {
      "metadata": {
        "id": "EsbelskbNbEl",
        "colab_type": "code",
        "outputId": "85277f97-dd81-4857-bd0e-25566efe0c5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 21632)             0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               2769024   \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,771,594\n",
            "Trainable params: 2,771,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 10s 165us/sample - loss: 0.3744 - acc: 0.8665\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.2487 - acc: 0.9091\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.2018 - acc: 0.9252\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.1654 - acc: 0.9383\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.1386 - acc: 0.9495\n",
            "10000/10000 [==============================] - 1s 71us/sample - loss: 0.2600 - acc: 0.9135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SVj80QXSN_2I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(3) Add more convolution"
      ]
    },
    {
      "metadata": {
        "id": "jo3941tdOE1h",
        "colab_type": "code",
        "outputId": "0e1cd1aa-847e-4066-ba99-62f1eac43ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 84,106\n",
            "Trainable params: 84,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.5759 - acc: 0.7877\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.3804 - acc: 0.8600\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.3276 - acc: 0.8787\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 9s 155us/sample - loss: 0.2926 - acc: 0.8910\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.2662 - acc: 0.9005\n",
            "10000/10000 [==============================] - 1s 72us/sample - loss: 0.3174 - acc: 0.8838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q41N0ZUfOpEv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(4) Run more epochs."
      ]
    },
    {
      "metadata": {
        "id": "RaDKBueGOxjh",
        "colab_type": "code",
        "outputId": "a95a875c-3fe2-4580-eabf-34b155fdf241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 113,386\n",
            "Trainable params: 113,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.4719 - acc: 0.8270\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3167 - acc: 0.8841\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2720 - acc: 0.9004\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2436 - acc: 0.9100\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2189 - acc: 0.9176\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1996 - acc: 0.9258\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1850 - acc: 0.9307\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.1675 - acc: 0.9371\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.1565 - acc: 0.9418\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1417 - acc: 0.9459\n",
            "10000/10000 [==============================] - 1s 78us/sample - loss: 0.2612 - acc: 0.9096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aRtU1P8FPW2Q",
        "colab_type": "code",
        "outputId": "bff724a5-5622-4600-a76a-057a9cb06180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_22 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               692352    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 693,962\n",
            "Trainable params: 693,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3985 - acc: 0.8607\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2681 - acc: 0.9029\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2230 - acc: 0.9176\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1896 - acc: 0.9297\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1626 - acc: 0.9393\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.1376 - acc: 0.9488\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1173 - acc: 0.9564\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0990 - acc: 0.9631\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0828 - acc: 0.9697\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0715 - acc: 0.9733\n",
            "10000/10000 [==============================] - 1s 68us/sample - loss: 0.3284 - acc: 0.9108\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}